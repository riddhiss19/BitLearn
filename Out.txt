Hey, guys, and welcome to another video from Fast Skills series.
In this video, I'm going to talk about a very interesting concept, which is parallel computing.
This topic or this way of computing, I should say, has been very, very popular in the past years.
And there's a specific reason why, which I'm going to discuss in this video.
But let's have a look at traditional computing, the type of computing which is not parallel.
So we have the processor here and the instructions come in and the processor does the processing and then you have the processed data here.
As you can see, there's a queue of new instructions coming in and the processor is doing its job and then we get kind of processed data out of it.
Now there's a problem with this approach, especially in the past couple of years, and the problem is that we can only make this processor faster to a limit.
There is a frequency limit.
And the reason there are plenty of reasons, actually, but one of the important ones is heat, because these processors are very, very kind of condensed.
So the amount of heat generated by electrons moving through the processor is very, very high.
And that's one of the reasons why we can really increase the speed of processors, one single processor, because it will melt down.
So because of this reason, we had to take a different approach.
So if we want to increase the speed, but we can really increase the speed in one single processor because of heat, then what can we do?
So one thing we can do is to increase the number of processors.
This way we have two processors running simultaneously and we divide the tasks between these two processors.
This is called parallel computing to processor running at the same time doing the calculations and we divide the workload between these two processors.
Of course, this introduces a new set of potential problems and one of them is more bugs because you should know when the first which instructions you need to divide and what instructions need to be dedicated to each of these processors.
Because let's say that you assign a kind of a process to this processor here and that task gets done fast.
But this task is dependent on a process which is currently being run by the other process here.
So you can have a kind of a latencies, you can have different kind of problems when it comes to writing programs for parallel systems.
Of course, majority of computers, especially since past couple of years, are all the computers are running on multiple multicore processors.
So that's another thing.
Each processor in the modern come to computing is called a core.
So a quad core, a dual core.
And that's basically that explains the number of processors running at the same time.
So this is a very, very short video on what parallel computing is.
We also have distributed computing, which is the subject of another video.
Thanks for watching this video and I'll see you later.
Bye.